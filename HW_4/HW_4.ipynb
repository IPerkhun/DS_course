{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(path):\n",
    "    with open(path) as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "path_train_neg = '../res/aclImdb/train/neg/'\n",
    "path_train_pos = '../res/aclImdb/train/pos/'\n",
    "\n",
    "train = [{'Class': 0, 'text': get_text(path_train_neg + x), } for x in os.listdir(path_train_neg)]\\\n",
    "+ [{'Class': 1, 'text': get_text(path_train_pos + x)} for x in os.listdir(path_train_pos)]\n",
    "\n",
    "\n",
    "path_test_neg = '../res/aclImdb/test/neg/'\n",
    "path_test_pos = '../res/aclImdb/test/pos/'\n",
    "\n",
    "\n",
    "test = [{'Class': 0, 'text': get_text(path_test_neg + x), } for x in os.listdir(path_test_neg)]\\\n",
    "+ [{'Class': 1, 'text': get_text(path_test_pos + x)} for x in os.listdir(path_test_pos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = re.sub(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\", ' ', reviews)\n",
    "    return \" \".join(reviews.split())\n",
    "\n",
    "df.text = df.text.apply(preprocess_reviews)\n",
    "df['tokenize'] = df.text.apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "def lemmatizer(tokens):\n",
    "    res = []\n",
    "    for token in tokens:\n",
    "        token = re.sub(\"[\\W\\d]\", '', token.lower())\n",
    "        if token not in stopwords.words('english') and token != '':\n",
    "            if wnl.lemmatize(token, pos='v') == token:\n",
    "                res.append(wnl.lemmatize(token, pos='n'))\n",
    "            else:\n",
    "                res.append(wnl.lemmatize(token, pos='v'))\n",
    "        else:\n",
    "            continue\n",
    "    return res\n",
    "\n",
    "df['clean_review'] = df.tokenize.apply(lemmatizer, )\n",
    "df.to_json('data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Working with one of the best Shakespeare sourc...</td>\n",
       "      <td>[Working, with, one, of, the, best, Shakespear...</td>\n",
       "      <td>work one best shakespeare source film manage c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Well...tremors I, the original started off in ...</td>\n",
       "      <td>[Well, ..., tremors, I, ,, the, original, star...</td>\n",
       "      <td>well tremor original start find movie quite en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>I felt brain dead, I'll tell you. This is the ...</td>\n",
       "      <td>[I, felt, brain, dead, ,, I, 'll, tell, you, ....</td>\n",
       "      <td>felt brain dead tell worst film ever buy ignor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>Really an amazing pile of pap! A predictable, ...</td>\n",
       "      <td>[Really, an, amazing, pile, of, pap, !, A, pre...</td>\n",
       "      <td>really amaze pile pap predictable slow move so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0</td>\n",
       "      <td>From everything I'd read about the movie, I wa...</td>\n",
       "      <td>[From, everything, I, 'd, read, about, the, mo...</td>\n",
       "      <td>everything read movie excite support film chri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class                                               text  \\\n",
       "0         0  Working with one of the best Shakespeare sourc...   \n",
       "1         0  Well...tremors I, the original started off in ...   \n",
       "10        0  I felt brain dead, I'll tell you. This is the ...   \n",
       "100       0  Really an amazing pile of pap! A predictable, ...   \n",
       "1000      0  From everything I'd read about the movie, I wa...   \n",
       "\n",
       "                                               tokenize  \\\n",
       "0     [Working, with, one, of, the, best, Shakespear...   \n",
       "1     [Well, ..., tremors, I, ,, the, original, star...   \n",
       "10    [I, felt, brain, dead, ,, I, 'll, tell, you, ....   \n",
       "100   [Really, an, amazing, pile, of, pap, !, A, pre...   \n",
       "1000  [From, everything, I, 'd, read, about, the, mo...   \n",
       "\n",
       "                                           clean_review  \n",
       "0     work one best shakespeare source film manage c...  \n",
       "1     well tremor original start find movie quite en...  \n",
       "10    felt brain dead tell worst film ever buy ignor...  \n",
       "100   really amaze pile pap predictable slow move so...  \n",
       "1000  everything read movie excite support film chri...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('../res/data.json', )\n",
    "df['clean_review'] = df.clean_review.apply(' '.join)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = df.sample(5000)\n",
    "x = df.clean_review\n",
    "y = df.Class\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "def get_top_terms(reviews, n):\n",
    "    res = []\n",
    "    for i in reviews:\n",
    "        tokens = word_tokenize(i)\n",
    "        res.extend(tokens)\n",
    "    res = Counter(res)\n",
    "    return res.most_common(n)\n",
    "\n",
    "neg = list(df[(df.Class == 1)]['clean_review'])\n",
    "pos = list(df[(df.Class == 0)]['clean_review'])\n",
    "\n",
    "top_negative_terms = pd.DataFrame.from_records(get_top_terms(neg, 10), columns=['word', 'freq'])\n",
    "top_positive_terms = pd.DataFrame.from_records(get_top_terms(pos, 10), columns=['word', 'freq'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15caa4d50>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "top_negative_terms.plot(kind='barh', x='word', figsize=(10,10))\n",
    "top_positive_terms.plot(kind='barh', x='word', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = list((set(top_negative_terms.word) & set(top_positive_terms.word))|set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.78\n",
      "{'clf__alpha': 14285.71437142857, 'clf__fit_prior': False, 'vect__max_features': 2550, 'vect__ngram_range': (1, 1)}\n",
      "accuracy before 0.8031111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.73      0.79      2277\n",
      "           1       0.76      0.88      0.82      2223\n",
      "\n",
      "    accuracy                           0.80      4500\n",
      "   macro avg       0.81      0.80      0.80      4500\n",
      "weighted avg       0.81      0.80      0.80      4500\n",
      "\n",
      "accuracy after 0.8064444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.74      0.79      2277\n",
      "           1       0.77      0.87      0.82      2223\n",
      "\n",
      "    accuracy                           0.81      4500\n",
      "   macro avg       0.81      0.81      0.81      4500\n",
      "weighted avg       0.81      0.81      0.81      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), max_features = 5000, stop_words = stop_words)),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB())\n",
    "              ])\n",
    "\n",
    "nb.fit(x_train, y_train)\n",
    "\n",
    "grid_params = {\n",
    "    'clf__alpha': np.linspace(1e-4, 1e+5, 8),\n",
    "    'clf__fit_prior': [True, False],\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__max_features': np.linspace(100, 5000, 5, dtype = np.int)\n",
    "}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(nb, grid_params, cv = 5, n_jobs=-1)\n",
    "clf.fit(x_train, y_train)\n",
    "print(\"Best Score: \", clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "y_pred = nb.predict(x_test)\n",
    "print('accuracy before %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "y_pred = clf.best_estimator_.predict(x_test)\n",
    "print('accuracy after %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.674\n",
      "{'clf__var_smoothing': 1e-09, 'vect__max_features': 100, 'vect__ngram_range': (1, 1)}\n",
      "accuracy before 0.6268888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.54      0.59      2277\n",
      "           1       0.60      0.72      0.65      2223\n",
      "\n",
      "    accuracy                           0.63      4500\n",
      "   macro avg       0.63      0.63      0.62      4500\n",
      "weighted avg       0.63      0.63      0.62      4500\n",
      "\n",
      "accuracy after 0.6788888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68      2277\n",
      "           1       0.68      0.67      0.67      2223\n",
      "\n",
      "    accuracy                           0.68      4500\n",
      "   macro avg       0.68      0.68      0.68      4500\n",
      "weighted avg       0.68      0.68      0.68      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), max_features = 5000, stop_words = stop_words)),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)), \n",
    "               ('clf', GaussianNB())\n",
    "              ])\n",
    "\n",
    "nb.fit(x_train, y_train)\n",
    "\n",
    "grid_params = {\n",
    "    'clf__var_smoothing': np.linspace(1e-9, 1e+5, 8),\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__max_features': np.linspace(100, 5000, 5, dtype = np.int)\n",
    "}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(nb, grid_params, cv = 5, n_jobs=-1)\n",
    "clf.fit(x_train, y_train)\n",
    "print(\"Best Score: \", clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "y_pred = nb.predict(x_test)\n",
    "print('accuracy before %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "y_pred = clf.best_estimator_.predict(x_test)\n",
    "print('accuracy after %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.752\n",
      "{'clf__alpha': 0.0001, 'vect__max_features': 1325, 'vect__ngram_range': (1, 2)}\n",
      "accuracy before 0.5046666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.04      2277\n",
      "           1       0.50      1.00      0.67      2223\n",
      "\n",
      "    accuracy                           0.50      4500\n",
      "   macro avg       0.75      0.51      0.35      4500\n",
      "weighted avg       0.75      0.50      0.35      4500\n",
      "\n",
      "accuracy after 0.7682222222222223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76      2277\n",
      "           1       0.74      0.82      0.78      2223\n",
      "\n",
      "    accuracy                           0.77      4500\n",
      "   macro avg       0.77      0.77      0.77      4500\n",
      "weighted avg       0.77      0.77      0.77      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), max_features = 5000, stop_words = stop_words)),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', BernoulliNB(binarize = None))\n",
    "              ])\n",
    "\n",
    "nb.fit(x_train, y_train)\n",
    "\n",
    "grid_params = {\n",
    "    'clf__alpha': np.linspace(1e-4, 1e+5, 8),\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__max_features': np.linspace(100, 5000, 5, dtype = np.int)\n",
    "}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(nb, grid_params, cv = 5, n_jobs=-1)\n",
    "clf.fit(x_train, y_train)\n",
    "print(\"Best Score: \", clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "y_pred = nb.predict(x_test)\n",
    "print('accuracy before %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "y_pred = clf.best_estimator_.predict(x_test)\n",
    "print('accuracy after %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.786\n",
      "{'clf__alpha': 14285.71437142857, 'clf__fit_prior': True, 'vect__max_features': 2000, 'vect__ngram_range': (1, 1)}\n",
      "accuracy before 0.8084444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.80      2277\n",
      "           1       0.79      0.84      0.81      2223\n",
      "\n",
      "    accuracy                           0.81      4500\n",
      "   macro avg       0.81      0.81      0.81      4500\n",
      "weighted avg       0.81      0.81      0.81      4500\n",
      "\n",
      "accuracy after 0.8066666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.80      2277\n",
      "           1       0.78      0.86      0.81      2223\n",
      "\n",
      "    accuracy                           0.81      4500\n",
      "   macro avg       0.81      0.81      0.81      4500\n",
      "weighted avg       0.81      0.81      0.81      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer(max_features = 5000, stop_words = stop_words)),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', ComplementNB())\n",
    "              ])\n",
    "\n",
    "nb.fit(x_train, y_train)\n",
    "\n",
    "grid_params = {\n",
    "    'clf__alpha': np.linspace(1e-4, 1e+5, 8),\n",
    "    'clf__fit_prior': [True, False],\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__max_features': np.linspace(1000, 5000, 5, dtype = np.int),\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(nb, grid_params, cv = 5, n_jobs=-1)\n",
    "clf.fit(x_train, y_train)\n",
    "print(\"Best Score: \", clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "y_pred = nb.predict(x_test)\n",
    "print('accuracy before %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "y_pred = clf.best_estimator_.predict(x_test)\n",
    "print('accuracy after %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.774\n",
      "{'clf__alpha': 0.0001, 'clf__penalty': 'l1', 'vect__max_features': 3000, 'vect__ngram_range': (1, 2)}\n",
      "accuracy 0.7926666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79      2277\n",
      "           1       0.78      0.81      0.79      2223\n",
      "\n",
      "    accuracy                           0.79      4500\n",
      "   macro avg       0.79      0.79      0.79      4500\n",
      "weighted avg       0.79      0.79      0.79      4500\n",
      "\n",
      "accuracy after 0.7755555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      2277\n",
      "           1       0.76      0.80      0.78      2223\n",
      "\n",
      "    accuracy                           0.78      4500\n",
      "   macro avg       0.78      0.78      0.78      4500\n",
      "weighted avg       0.78      0.78      0.78      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "\n",
    "sgdc = Pipeline([('vect', CountVectorizer(ngram_range=(1, 1), max_features = 5000, stop_words = stop_words)),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', SGDClassifier())\n",
    "              ])\n",
    "\n",
    "sgdc.fit(x_train, y_train)\n",
    "\n",
    "grid_params = {\n",
    "    'clf__alpha':  np.linspace(1e-4, 1e+5, 8),\n",
    "    'clf__penalty': ['l2', 'l1'],\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__max_features': np.linspace(1000, 5000, 5, dtype = np.int),\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(sgdc, grid_params, cv = 5, n_jobs=-1)\n",
    "clf.fit(x_train, y_train)\n",
    "print(\"Best Score: \", clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "y_pred = sgdc.predict(x_test)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "y_pred = clf.best_estimator_.predict(x_test)\n",
    "print('accuracy after %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1280 candidates, totalling 3840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3840 out of 3840 | elapsed:  8.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.7899622441863262\n",
      "Best Params:  {'clf__C': 14285.71437142857, 'clf__degree': 2, 'clf__gamma': 'scale', 'clf__kernel': 'rbf', 'clf__max_iter': 5000, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "accuracy 0.7966666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.69      0.78      2277\n",
      "           1       0.74      0.90      0.81      2223\n",
      "\n",
      "    accuracy                           0.80      4500\n",
      "   macro avg       0.81      0.80      0.79      4500\n",
      "weighted avg       0.81      0.80      0.79      4500\n",
      "\n",
      "accuracy after 0.792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.79      2277\n",
      "           1       0.77      0.83      0.80      2223\n",
      "\n",
      "    accuracy                           0.79      4500\n",
      "   macro avg       0.79      0.79      0.79      4500\n",
      "weighted avg       0.79      0.79      0.79      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "\n",
    "svm = Pipeline([('vect', CountVectorizer(ngram_range=(1, 1), max_features = 5000, stop_words = stop_words)),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', SVC(max_iter = 5000, kernel = 'rbf'))\n",
    "              ])\n",
    "\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "grid_params = {\n",
    "    \n",
    "    'clf__C':  np.linspace(1e-4, 1e+5, 8),\n",
    "    'clf__kernel':  ['sigmoid', 'linear', 'poly', 'rbf'],\n",
    "    'clf__degree': [2, 3],\n",
    "    'clf__max_iter': [5000],\n",
    "    'clf__gamma': ['scale', 'auto'],\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__max_features': np.linspace(1000, 5000, 5, dtype = np.int)\n",
    "    \n",
    "}\n",
    "\n",
    "clf = GridSearchCV(svm, grid_params, cv = 3, verbose= True, n_jobs=-1)\n",
    "clf.fit(x_train, y_train)\n",
    "print(\"Best Score: \", clf.best_score_)\n",
    "print(\"Best Params: \", clf.best_params_)\n",
    "\n",
    "y_pred = svm.predict(x_test)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "y_pred = clf.best_estimator_.predict(x_test)\n",
    "print('accuracy after %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Лучше всего себя покзаал MultinomialNB класификатор\n",
    "- В качетсве стоп слов использовалось пересечения множетсва полпулярных нег. и позит. терминов вместе с стандартными набором английских стоп слов\n",
    "____\n",
    "`\n",
    "Best Score:  0.806\n",
    "Best Params:  \n",
    "'clf__C': 14285.7143, \n",
    "'clf__fit_prior': False, \n",
    "'clf__max_iter': 5000, \n",
    "'vect__max_features': 2550, \n",
    "'vect__ngram_range': (1, 1)\n",
    "`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
